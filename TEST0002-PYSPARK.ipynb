{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781afc3f-0424-4542-b51c-dc3f4d67d252",
   "metadata": {},
   "source": [
    "<img src=\"https://i.pinimg.com/originals/ee/2e/24/ee2e246795a13abc1fe01b28776626ef.jpg\" alt= \"LOGO CAT\" width=400 height=400 align = \"right\">\n",
    "\n",
    "<br>\n",
    "<h1><font color=\"#7F000E\" size=5>INSTITUTO GEOFISICO DEL PERU</font></h1>\n",
    "<h1><font color=\"#7F000R\" size=6> SPARK Y PYTHON CON PYSPARK </font></h1>\n",
    "<h1><font color=\"#7F000E\" size=4> SEGUNDA PRUEBA Y EJEMPLOS\n",
    " </font></h1>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align:left\">\n",
    "<font color=\"#7F000E\" size=3> Ing. Alexander Valdez</font><br>\n",
    "<font color=\"#7F000E\" size=3> Libertad Financiera </font><br>\n",
    "<font color=\"#7F000e\" size=3> Segunda Clase </font><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512ccbc-6eed-4868-9c09-378c74308259",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2968f2b-622c-4e05-ac99-177c7989c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e21c73-adf0-413a-8985-6e102485f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf78367-c58d-4586-b1e0-467dc93e5171",
   "metadata": {},
   "source": [
    "# Creacion de Sesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0183a7-60f9-46d1-967a-5f8854fc6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce2916-8f5f-4cb5-a49f-6bf04eacba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "type(pd.read_csv('Book1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f06900-9335-4853-8656-89f10021feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed059808-d12f-4242-afb7-003495b1be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298ec8a-4006-45d8-8d27-740e4d281027",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09759798-b734-41d8-a332-47868a06d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214322dd-9a45-4ade-8f8f-4a6816bd6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f44b8-6b2d-41fb-b3cf-365713186ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_= spark.read.option('header','true').csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c1d70-5993-4eab-81d7-73cb6e7304b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_pyspark_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cec8da-6c13-4e97-a5ad-caada94b5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3742afc-6c6f-4a2b-a8f2-7b3894c68e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69257a-0dab-4135-bf43-ab702b69cc25",
   "metadata": {},
   "source": [
    "En este tutorial vamos a cubrir los siguientes conceptos:\n",
    "* PySpark Dataframe.\n",
    "*  Lectura del dataset.\n",
    "*  Revision de los datatypes de las columnas(Schema).\n",
    "*  Seleccion de columnas e indexing.\n",
    "*  Revision de la descripcion y opciones similares de pandas.\n",
    "*  AÃ±adir columnas.\n",
    "*  Eliminarn columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d0bcd8-6d3d-46f9-b2a5-5f28bd9e0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea2a921-b518-4102-a7da-1df2f39c78ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3609fe29-c2d2-4195-a55a-63f7d05fc31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-G5VMGK2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x227ce63eb80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989e097-bd3e-4ccd-8769-68d068283f14",
   "metadata": {},
   "source": [
    "## read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b126b640-42ae-4468-aabf-3a51ac1f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= spark.read.option('header','true').csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8d1437d-8920-4066-8a98-06860a97f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7453f915-68cc-4699-ae9e-82f08813a92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40369dd9-40ad-46fc-857b-61167f99661a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Wendy', age='31', Experience=' 4'),\n",
       " Row(Name='Maria Paz', age='1', Experience='1'),\n",
       " Row(Name='Alexander', age='34', Experience='10')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e82692ab-9af1-466c-a2b5-796c7a72d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f50ce6a-02ea-4d16-a2f5-76123a8b4d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELECCIONAR COLUMNA NOMBRE\n",
    "df_pyspark.select('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5feb3749-7097-4f52-9904-1c839f02866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Experience: string]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(['Name','Experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c53f045-461f-443c-88c2-c327d24b0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|    Wendy|         4|\n",
      "|Maria Paz|         1|\n",
      "|Alexander|        10|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name','Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f302aba-2959-4e08-a107-4d9057589f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d387bb1-d48d-4202-b8ba-7a2b93e7cf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'string'), ('Experience', 'string')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f7ca579-1d1d-470c-8ac5-32aea2fe9665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, age: string, Experience: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa574168-f8e5-4433-9f97-ad49fe100016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+----------------+\n",
      "|summary|     Name|              age|      Experience|\n",
      "+-------+---------+-----------------+----------------+\n",
      "|  count|        3|                3|               3|\n",
      "|   mean|     NULL|             22.0|             5.0|\n",
      "| stddev|     NULL|18.24828759089466|4.58257569495584|\n",
      "|    min|Alexander|                1|               1|\n",
      "|    max|    Wendy|               34|               4|\n",
      "+-------+---------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f73dd-8417-45fb-b097-e2e75ea9fbf3",
   "metadata": {},
   "source": [
    "### Adding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91b85b3d-8b45-4667-80bd-a53390c3bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: string, Experience: string, Experience After 2 Year: double]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumn('Experience After 2 Year',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "266c0b38-f2e8-48fa-a546-c4c07111e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+-----------------------+\n",
      "|     Name|age|Experience|Experience After 2 Year|\n",
      "+---------+---+----------+-----------------------+\n",
      "|    Wendy| 31|         4|                    6.0|\n",
      "|Maria Paz|  1|         1|                    3.0|\n",
      "|Alexander| 34|        10|                   12.0|\n",
      "+---------+---+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumn('Experience After 2 Year',df_pyspark['Experience']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "626ddb6a-33b7-4063-962c-e9d0d0786bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "|     Name|age|Experience|\n",
      "+---------+---+----------+\n",
      "|    Wendy| 31|         4|\n",
      "|Maria Paz|  1|         1|\n",
      "|Alexander| 34|        10|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7ccf452-f598-408d-a396-3ae3d7f3466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('Experience After 2 Year',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fed18fdf-3734-4536-82db-61983e60958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+-----------------------+\n",
      "|     Name|age|Experience|Experience After 2 Year|\n",
      "+---------+---+----------+-----------------------+\n",
      "|    Wendy| 31|         4|                    6.0|\n",
      "|Maria Paz|  1|         1|                    3.0|\n",
      "|Alexander| 34|        10|                   12.0|\n",
      "+---------+---+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2d1aa-ef3f-491a-9c38-5392c7b9e1f7",
   "metadata": {},
   "source": [
    "## DROP THE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8e15cad-5bfd-40d0-9626-e54e9d87eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('Experience After 2 year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c3b90b5-85e1-4726-bcf8-3731760a7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "|     Name|age|Experience|\n",
      "+---------+---+----------+\n",
      "|    Wendy| 31|         4|\n",
      "|Maria Paz|  1|         1|\n",
      "|Alexander| 34|        10|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592910d1-c0d5-45fb-b448-42e4e6945ff9",
   "metadata": {},
   "source": [
    "## RENAME THE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e4eae7a-cd17-4bef-863f-3dd44451c7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "| New Name|age|Experience|\n",
      "+---------+---+----------+\n",
      "|    Wendy| 31|         4|\n",
      "|Maria Paz|  1|         1|\n",
      "|Alexander| 34|        10|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('Name','New Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cffbe9-3843-4d68-8ce4-72ad27bce71c",
   "metadata": {},
   "source": [
    "# Pyspark Handling Missing Values\n",
    "* Dropping Columns.\n",
    "* Dropping Rows.\n",
    "* Various Parameter in Dropping functionalities.\n",
    "* Handling Missing Values by Mean, median and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb62e1d6-19dd-4bd4-99a9-eed66dcd1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark =SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60defd8b-5fe0-4944-b850-ede2b51c9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= spark.read.csv('test2.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d2f06c-6dac-4f95-9449-acf63ad8fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Alex|  31|        10| 30000|\n",
      "| Wendy|  30|         8| 25000|\n",
      "|   Paz|  29|         4| 20000|\n",
      "| Boris|  24|         3| 20000|\n",
      "|  Ciro|  21|         1| 15000|\n",
      "|Silvia|  23|         2| 18000|\n",
      "|  Copo|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66013c06-2adb-4d57-a8d9-3ff9232d3582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        10| 30000|\n",
      "|  30|         8| 25000|\n",
      "|  29|         4| 20000|\n",
      "|  24|         3| 20000|\n",
      "|  21|         1| 15000|\n",
      "|  23|         2| 18000|\n",
      "|NULL|      NULL| 40000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## drop the columns\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e8000be-0d1c-4136-8d24-cd3c33fd0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         1| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8fe859-3111-4d74-ae29-f91eb49f54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Alex|  31|        10| 30000|\n",
      "| Wendy|  30|         8| 25000|\n",
      "|   Paz|  29|         4| 20000|\n",
      "| Boris|  24|         3| 20000|\n",
      "|  Ciro|  21|         1| 15000|\n",
      "|Silvia|  23|         2| 18000|\n",
      "|  Copo|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## any ==How\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8018588-15b7-4e19-a72d-b01a910235cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         1| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21242293-ccf1-4841-9214-b79458bf6db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         1| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "|  NULL| 34|        10| 38000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## threshold\n",
    "df_pyspark.na.drop(how=\"any\",thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "849bdaf1-1f6a-46f7-93a2-1b210f3d7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Alex|  31|        10| 30000|\n",
      "| Wendy|  30|         8| 25000|\n",
      "|   Paz|  29|         4| 20000|\n",
      "| Boris|  24|         3| 20000|\n",
      "|  Ciro|  21|         1| 15000|\n",
      "|Silvia|  23|         2| 18000|\n",
      "|  Copo|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## threshold,al menos dos valores no nulos\n",
    "df_pyspark.na.drop(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6e5258-646e-4617-891e-2650f49a04d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         1| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "|  NULL| 34|        10| 38000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=\"any\",subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d86cee32-d7b4-4a6a-940b-ac3b51d3131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Alex|  31|        10| 30000|\n",
      "| Wendy|  30|         8| 25000|\n",
      "|   Paz|  29|         4| 20000|\n",
      "| Boris|  24|         3| 20000|\n",
      "|  Ciro|  21|         1| 15000|\n",
      "|Silvia|  23|         2| 18000|\n",
      "|  Copo|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling the Missing Value\n",
    "df_pyspark.na.fill('Missing Values',['Experience','age']).show()b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e4a3e8c-2a4f-4f47-a3f1-d60b14ba8666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|          Alex|  31|        10| 30000|\n",
      "|         Wendy|  30|         8| 25000|\n",
      "|           Paz|  29|         4| 20000|\n",
      "|         Boris|  24|         3| 20000|\n",
      "|          Ciro|  21|         1| 15000|\n",
      "|        Silvia|  23|         2| 18000|\n",
      "|          Copo|NULL|      NULL| 40000|\n",
      "|Missing Values|  34|        10| 38000|\n",
      "|Missing Values|  36|      NULL|  NULL|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6609f81-0eac-4468-9f7e-df8d80d20aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Alex|  31|        10| 30000|\n",
      "| Wendy|  30|         8| 25000|\n",
      "|   Paz|  29|         4| 20000|\n",
      "| Boris|  24|         3| 20000|\n",
      "|  Ciro|  21|         1| 15000|\n",
      "|Silvia|  23|         2| 18000|\n",
      "|  Copo|NULL|      NULL| 40000|\n",
      "|  NULL|  34|        10| 38000|\n",
      "|  NULL|  36|      NULL|  NULL|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "147656fc-7bd3-4f9f-8655-903550ae8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(\n",
    "inputCols=['age','Experience','Salary'],\n",
    "outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2bcfc08-49d9-4e90-a1c8-6568970611a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Alex|  31|        10| 30000|         31|                10|         30000|\n",
      "| Wendy|  30|         8| 25000|         30|                 8|         25000|\n",
      "|   Paz|  29|         4| 20000|         29|                 4|         20000|\n",
      "| Boris|  24|         3| 20000|         24|                 3|         20000|\n",
      "|  Ciro|  21|         1| 15000|         21|                 1|         15000|\n",
      "|Silvia|  23|         2| 18000|         23|                 2|         18000|\n",
      "|  Copo|NULL|      NULL| 40000|         28|                 5|         40000|\n",
      "|  NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|  NULL|  36|      NULL|  NULL|         36|                 5|         25750|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99b94a0b-a3d5-494a-ac03-1cefe96650f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer=Imputer(\n",
    "inputCols=['age','Experience','Salary'],\n",
    "outputCols=[\"{}_imputed\".format(c) for c in ['age','Experience','Salary']]\n",
    ").setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dd7c4b2-e46b-4a48-93c9-ebace25b70cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Alex|  31|        10| 30000|         31|                10|         30000|\n",
      "| Wendy|  30|         8| 25000|         30|                 8|         25000|\n",
      "|   Paz|  29|         4| 20000|         29|                 4|         20000|\n",
      "| Boris|  24|         3| 20000|         24|                 3|         20000|\n",
      "|  Ciro|  21|         1| 15000|         21|                 1|         15000|\n",
      "|Silvia|  23|         2| 18000|         23|                 2|         18000|\n",
      "|  Copo|NULL|      NULL| 40000|         29|                 4|         40000|\n",
      "|  NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|  NULL|  36|      NULL|  NULL|         36|                 4|         20000|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358ef43-2e7a-4000-9d63-41582d15963c",
   "metadata": {},
   "source": [
    "# PYSPARK DATAFRAMES\n",
    "* Filter Operation\n",
    "*  &, |, ==\n",
    "*  ~\n",
    "\n",
    "  FUNCIONAMIENTO DEL FILTRO y operaciones booleanas\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9758a94-87b6-4665-9b76-acce21c6f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f6f031c-46a8-42c6-b1d8-44f8c91c1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ad27071-7ea0-4691-8ae7-d47ca66c7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('Book2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ec1fef3-dc86-4e12-8503-1934aefed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|   _c0|_c1|       _c2|   _c3|\n",
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         3| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8f8fbda-b341-481c-b68f-16167e38bf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         3| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('Book2.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d9fa6-4b05-459d-9bcb-886ca88990c8",
   "metadata": {},
   "source": [
    "### FILTER OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d752c72c-8a9b-49fe-a628-5019f8e15281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         3| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Salary of the people less than or equal to 20000\n",
    "df_pyspark.filter(\"Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d510e57a-645a-46e5-a55d-5c1ac88c8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|age|\n",
      "+------+---+\n",
      "|   Paz| 29|\n",
      "| Boris| 24|\n",
      "|  Ciro| 21|\n",
      "|Silvia| 23|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4305eba-a673-41f4-ac94-b3b3988c7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Alex| 31|        10| 30000|\n",
      "| Wendy| 30|         8| 25000|\n",
      "|   Paz| 29|         4| 20000|\n",
      "| Boris| 24|         3| 20000|\n",
      "|  Ciro| 21|         3| 15000|\n",
      "|Silvia| 23|         2| 18000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Salary']<=20000) | (df_pyspark['Salary']>=15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01ddf749-cffe-4288-9f2a-74091fe3aba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "| Alex| 31|        10| 30000|\n",
      "|Wendy| 30|         8| 25000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b81adc-1caf-41ec-b309-7ee4d6d9f794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
